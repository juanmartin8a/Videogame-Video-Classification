{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06h72qsZ0Fm7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJL4Z3IN0Foo"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "MAX_SEQ_LENGTH = 25\n",
        "NUM_FEATURES = 55296"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBtAb_qV0Fqv"
      },
      "outputs": [],
      "source": [
        "def load_video(path, resize=(IMG_SIZE, IMG_SIZE)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    numberOfFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT);\n",
        "\n",
        "    skip_number = int(numberOfFrames) // MAX_SEQ_LENGTH\n",
        "\n",
        "    try:\n",
        "        for i in range(0, int(numberOfFrames), skip_number):\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frames.append(np.array(frame) / 255)\n",
        "            if len(frames) == MAX_SEQ_LENGTH:\n",
        "                break\n",
        "\n",
        "    finally:\n",
        "        cap.release()\n",
        "\n",
        "    return np.array(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFPU0_ky0Fsr",
        "outputId": "b33d88f2-ec34-47d7-aea0-5e81004b57c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/layers/core.py:1045: UserWarning: tensorflow.python.keras.applications.inception_resnet_v2 is not loaded, but a Lambda layer uses it. It may cause errors.\n",
            "  , UserWarning)\n"
          ]
        }
      ],
      "source": [
        "def featureExtractor():\n",
        "    feature_extractor = tf.keras.models.load_model(\"/content/drive/MyDrive/weights-14.hdf5\");\n",
        "    return Model(feature_extractor.input, feature_extractor.layers[-2].output)\n",
        "feature_extractor = featureExtractor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAysSmLo0Fuy"
      },
      "outputs": [],
      "source": [
        "def load_all_videos(tags, paths, test_train, root_dir):\n",
        "#     print(tags)\n",
        "    train_features = []\n",
        "    train_labels = []\n",
        "\n",
        "    test_features = []\n",
        "    test_labels = []\n",
        "\n",
        "    for i, path in enumerate(paths):\n",
        "        final_path = os.path.join(root_dir, path)\n",
        "        frames = load_video(final_path)\n",
        "        frames = frames[None, ...]\n",
        "\n",
        "        for frame in frames:\n",
        "            prediction = feature_extractor.predict(frame)\n",
        "            if (test_train[i] == 'train'):\n",
        "                train_features.append(prediction)\n",
        "                train_labels.append(tags[i])\n",
        "            else:\n",
        "                test_features.append(prediction)\n",
        "                test_labels.append(tags[i])\n",
        "\n",
        "    return np.array(train_features), np.array(train_labels), np.array(test_features), np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoSqMWlc0Fw5"
      },
      "outputs": [],
      "source": [
        "tags = []\n",
        "paths = []\n",
        "test_train = []\n",
        "with open(\"videogamesVideosDataset/data_file.csv\") as f:\n",
        "    reader = csv.reader(f, delimiter=\"\\t\")\n",
        "    for i in reader:\n",
        "        tags.append(i[0].split(',')[2])\n",
        "        paths.append(i[0].split(',')[3])\n",
        "        test_train.append(i[0].split(',')[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cBH-qko0Fyp"
      },
      "outputs": [],
      "source": [
        "train_features, train_labels, test_features, test_labels = load_all_videos(tags, paths, test_train, \"videogamesVideosDataset/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFoL5G810F0_"
      },
      "outputs": [],
      "source": [
        "def lstmModel():\n",
        "    model = Sequential()\n",
        "#     model.add(Embedding(25, 512))\n",
        "    model.add(LSTM(1024, return_sequences=False,\n",
        "                   input_shape=(MAX_SEQ_LENGTH, 55296),\n",
        "                   dropout=0.5))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(21, activation='softmax'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayJGixpY0kKh"
      },
      "outputs": [],
      "source": [
        "model = lstmModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKBNuZ4x0m7J",
        "outputId": "3c0e8c36-d7a2-4054-f71f-a7b82b4ab92b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqupBitO0m9D"
      },
      "outputs": [],
      "source": [
        "checkpointer = ModelCheckpoint('/content/drive/MyDrive/weights-lstm.hdf5', monitor='val_loss', verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CTyw9GW0m-0"
      },
      "outputs": [],
      "source": [
        "le = preprocessing.LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_vJc8Cc0p5K"
      },
      "outputs": [],
      "source": [
        "le.fit(test_labels)\n",
        "test_labels = le.transform(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3nmMvIf0p7P"
      },
      "outputs": [],
      "source": [
        "le.fit(train_labels)\n",
        "train_labels = le.transform(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulGk4EwT0p9l"
      },
      "outputs": [],
      "source": [
        "test_labels = tf.one_hot(test_labels, 21)\n",
        "train_labels = tf.one_hot(train_labels, 21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uTEIhvS0qQN",
        "outputId": "3c94aa33-2192-4797-eee3-9f7c449e64a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "15/15 [==============================] - 15s 840ms/step - loss: 1.5431 - accuracy: 0.6203 - val_loss: 0.3119 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.31187, saving model to /content/drive/MyDrive/weights-lstm.hdf5\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 13s 827ms/step - loss: 0.2706 - accuracy: 0.9581 - val_loss: 0.1280 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.31187 to 0.12797, saving model to /content/drive/MyDrive/weights-lstm.hdf5\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 12s 779ms/step - loss: 0.1195 - accuracy: 0.9845 - val_loss: 0.0797 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.12797 to 0.07972, saving model to /content/drive/MyDrive/weights-lstm.hdf5\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 12s 776ms/step - loss: 0.0551 - accuracy: 0.9978 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.07972 to 0.04810, saving model to /content/drive/MyDrive/weights-lstm.hdf5\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 12s 780ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9899\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.04810 to 0.04188, saving model to /content/drive/MyDrive/weights-lstm.hdf5\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 12s 784ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.04188 to 0.03564, saving model to /content/drive/MyDrive/weights-lstm.hdf5\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 12s 780ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.03564 to 0.02870, saving model to /content/drive/MyDrive/weights-lstm.hdf5\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 12s 784ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.02870\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 12s 782ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.02870 to 0.02436, saving model to /content/drive/MyDrive/weights-lstm.hdf5\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 12s 787ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.02436 to 0.01722, saving model to /content/drive/MyDrive/weights-lstm.hdf5\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 12s 786ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01722\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 12s 788ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01722\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 12s 795ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01722\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 12s 788ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01722 to 0.01339, saving model to /content/drive/MyDrive/weights-lstm.hdf5\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 12s 783ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01339\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 12s 794ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9899\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01339\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 12s 787ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01339\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 12s 787ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01339\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 12s 790ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01339\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 12s 793ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01339 to 0.01260, saving model to /content/drive/MyDrive/weights-lstm.hdf5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f074366a950>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "#     batch_size=BATCH_SIZE,\n",
        "    validation_data = (test_features, test_labels),\n",
        "    epochs = EPOCHS,\n",
        "    callbacks=[checkpointer]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5DHnLxz1aC_"
      },
      "outputs": [],
      "source": [
        "class_labels = [\n",
        "  'Apex',\n",
        "  'Csgo',\n",
        "  'Clash Royale',\n",
        "  \"Deadth By Daylight\",\n",
        "  'Dota2',\n",
        "  \"Escape From Tarkov\",\n",
        "  \"Fifa21\",\n",
        "  \"Fortnite\",\n",
        "  \"Free fire\",\n",
        "  \"GtaV\",\n",
        "  \"Lol\",\n",
        "  \"Minecraft\",\n",
        "  \"Overwatch\",\n",
        "  \"pubg\",\n",
        "  \"rainbows\",\n",
        "  \"rocket league\",\n",
        "  \"rust\",\n",
        "  \"sea of thieves\",\n",
        "  \"valorant\",\n",
        "  \"warzone\",\n",
        "  \"wow\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-mXRG_AxKIS"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/warzone_2.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8WPZYn2xKKa"
      },
      "outputs": [],
      "source": [
        "frames = load_video(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0cjKgIzsJX-"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/weights-lstm.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8goQI-yOzIf_"
      },
      "outputs": [],
      "source": [
        "features = []\n",
        "frames = frames[None, ...]\n",
        "for frame in frames:\n",
        "  # print(frame.shape)\n",
        "  cnn_prediction = feature_extractor.predict(frame)\n",
        "  features.append(cnn_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMigd3gr0H8f"
      },
      "outputs": [],
      "source": [
        "features = np.array(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqLwXkF7yZzb"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq-2Kv5o1Uzy",
        "outputId": "96e22477-3ddd-479e-ad82-c10bb44e1103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0. 100.   0.]\n",
            "warzone: 100.0\n"
          ]
        }
      ],
      "source": [
        "prediction_array = np.array(prediction[0])\n",
        "prediction_array = prediction_array.round(decimals=3)\n",
        "prediction_array = prediction_array * 100\n",
        "print(prediction_array)\n",
        "\n",
        "top1Arg = prediction_array.argmax()\n",
        "top_1_prediction = prediction_array[top1Arg]\n",
        "top_1_label = class_labels[top1Arg]\n",
        "\n",
        "print(f\"{top_1_label}: {top_1_prediction}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
